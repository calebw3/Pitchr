{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pitchr import data\n",
    "from pitchr import xml_parser\n",
    "from pitchr import harmony_maker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Flatten, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "DATA_PATH = \"../dataset/_xml_scores\"\n",
    "score_files = os.listdir(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210 210\n"
     ]
    }
   ],
   "source": [
    "# gets list of all melody and harmony dfs\n",
    "all_melody_dfs, all_harmony_dfs = xml_parser.get_all_data()\n",
    "print(len(all_melody_dfs), len(all_harmony_dfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Converting dfs to numpy arrays\n",
    "minimum_melody = 999\n",
    "minimum_harmony = 999\n",
    "all_melody_np = []\n",
    "all_harmony_np = []\n",
    "for df in all_melody_dfs:\n",
    "    df = df[['Pitch Number', 'Pitch Interval', 'Pitch Predictability']]\n",
    "    temp_np = df.to_numpy()\n",
    "    all_melody_np.append(temp_np)\n",
    "for df in all_harmony_dfs:\n",
    "    df = df[['Pitch Number', 'Pitch Interval', 'Pitch Predictability']]\n",
    "    temp_np = df.to_numpy()\n",
    "    all_harmony_np.append(temp_np)\n",
    "\n",
    "\n",
    "# normalize harmony sizes\n",
    "all_harmony_np = xml_parser.prepare_harmony(all_harmony_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dataframes to numpy arrays\n",
    "all_melody_np = np.asarray(all_melody_np)\n",
    "all_harmony_np = np.asarray(all_harmony_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210, 50, 3)\n",
      "(210, 50, 3)\n",
      "43.0 33.0 1.0\n"
     ]
    }
   ],
   "source": [
    "# convert all values to floats\n",
    "# min pitch number is -33\n",
    "# max pitch number is 43\n",
    "\n",
    "for array in all_melody_np:\n",
    "    for note in array:\n",
    "        for i in range(0, 3):\n",
    "            if type(note[i]) == str:\n",
    "                note[i] = float(-50)\n",
    "                np.float32\n",
    "            elif type(note[i]) == int:\n",
    "                note[i] = float(note[i])\n",
    "for array in all_harmony_np:\n",
    "    for note in array:\n",
    "        for i in range(0, 3):\n",
    "            if type(note[i]) == str:\n",
    "                note[i] = float(-50)\n",
    "            elif type(note[i]) == int:\n",
    "                note[i] = float(note[i])\n",
    "\n",
    "\n",
    "                \n",
    "max_pitch_number = -50\n",
    "max_interval = -50\n",
    "max_predictability = -50\n",
    "for array in all_melody_np:\n",
    "    for note in array:\n",
    "        if note[0] > max_pitch_number:\n",
    "            max_pitch_number = note[0]\n",
    "        if note[1] > max_interval:\n",
    "            max_interval = note[1]\n",
    "        if note[2] > max_predictability:\n",
    "            max_predictability = note[2]\n",
    "for array in all_harmony_np:\n",
    "    for note in array:\n",
    "        if note[0] > max_pitch_number:\n",
    "            max_pitch_number = note[0]\n",
    "        if note[1] > max_interval:\n",
    "            max_interval = note[1]\n",
    "        if note[2] > max_predictability:\n",
    "            max_predictability = note[2]\n",
    "\n",
    "print(all_melody_np.shape)\n",
    "print(all_harmony_np.shape)\n",
    "print(max_pitch_number, max_interval, max_predictability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = tf.convert_to_tensor(all_melody_np, dtype=tf.float32)\n",
    "Y = tf.convert_to_tensor(all_harmony_np, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(151, 50, 3) (151, 50, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(all_melody_np, all_harmony_np, test_size=0.2)\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(x_train, y_train, test_size=0.1)\n",
    "print(x_train.shape, y_train.shape)\n",
    "x_train = tf.convert_to_tensor(x_train, dtype=tf.float32)\n",
    "y_train = tf.convert_to_tensor(y_train, dtype=tf.float32)\n",
    "normalized_x_train = x_train/50\n",
    "normalized_y_train = y_train/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(all_melody_np.shape)\n",
    "print(all_harmony_np.shape)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model = Sequential()\n",
    "# 2 LSTM layers\n",
    "model.add(LSTM(200, input_shape=(50, 3), return_sequences=True))\n",
    "model.add(LSTM(200))\n",
    "\n",
    "# Dense layers\n",
    "model.add(Dense(100, activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "model.summary()\n",
    "model.compile(optimizer=optimizer, loss='mse')\n",
    "print(model.summary())\n",
    "trained_model = model.fit(normalized_x_train, normalized_y_train, epochs=50, validation_split=0.2, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_8 (LSTM)                (None, 50, 512)           1056768   \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 512)               2099200   \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 3,188,995\n",
      "Trainable params: 3,188,995\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# trained model\n",
    "summary = model.summary()\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_28 (LSTM)               (None, 50, 200)           163200    \n",
      "_________________________________________________________________\n",
      "lstm_29 (LSTM)               (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 504,403\n",
      "Trainable params: 504,403\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_28 (LSTM)               (None, 50, 200)           163200    \n",
      "_________________________________________________________________\n",
      "lstm_29 (LSTM)               (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 504,403\n",
      "Trainable params: 504,403\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "120/120 [==============================] - 4s 31ms/step - loss: 0.3528 - val_loss: 0.2942\n",
      "Epoch 2/50\n",
      "120/120 [==============================] - 4s 29ms/step - loss: 0.3479 - val_loss: 0.2952\n",
      "Epoch 3/50\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3482 - val_loss: 0.2944\n",
      "Epoch 4/50\n",
      "120/120 [==============================] - 4s 32ms/step - loss: 0.3490 - val_loss: 0.2941\n",
      "Epoch 5/50\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3465 - val_loss: 0.2940\n",
      "Epoch 6/50\n",
      "120/120 [==============================] - 4s 37ms/step - loss: 0.3470 - val_loss: 0.2945\n",
      "Epoch 7/50\n",
      "120/120 [==============================] - 6s 46ms/step - loss: 0.3474 - val_loss: 0.2951\n",
      "Epoch 8/50\n",
      "120/120 [==============================] - 5s 43ms/step - loss: 0.3479 - val_loss: 0.2935\n",
      "Epoch 9/50\n",
      "120/120 [==============================] - 5s 39ms/step - loss: 0.3463 - val_loss: 0.2940\n",
      "Epoch 10/50\n",
      "120/120 [==============================] - 5s 40ms/step - loss: 0.3478 - val_loss: 0.2944\n",
      "Epoch 11/50\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.3472 - val_loss: 0.2941\n",
      "Epoch 12/50\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.3471 - val_loss: 0.2940\n",
      "Epoch 13/50\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.3467 - val_loss: 0.2939\n",
      "Epoch 14/50\n",
      "120/120 [==============================] - 5s 44ms/step - loss: 0.3471 - val_loss: 0.2931\n",
      "Epoch 15/50\n",
      "120/120 [==============================] - 6s 49ms/step - loss: 0.3457 - val_loss: 0.2935\n",
      "Epoch 16/50\n",
      "120/120 [==============================] - 5s 45ms/step - loss: 0.3460 - val_loss: 0.2934\n",
      "Epoch 17/50\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.3474 - val_loss: 0.2933\n",
      "Epoch 18/50\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3465 - val_loss: 0.2933\n",
      "Epoch 19/50\n",
      "120/120 [==============================] - 4s 32ms/step - loss: 0.3472 - val_loss: 0.2934\n",
      "Epoch 20/50\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.3463 - val_loss: 0.2932\n",
      "Epoch 21/50\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.3464 - val_loss: 0.2936\n",
      "Epoch 22/50\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.3473 - val_loss: 0.2925\n",
      "Epoch 23/50\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.3465 - val_loss: 0.2929\n",
      "Epoch 24/50\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3468 - val_loss: 0.2914\n",
      "Epoch 25/50\n",
      "120/120 [==============================] - 5s 40ms/step - loss: 0.3464 - val_loss: 0.2938\n",
      "Epoch 26/50\n",
      "120/120 [==============================] - 5s 42ms/step - loss: 0.3470 - val_loss: 0.2906\n",
      "Epoch 27/50\n",
      "120/120 [==============================] - 4s 37ms/step - loss: 0.3465 - val_loss: 0.2910\n",
      "Epoch 28/50\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.3464 - val_loss: 0.2909\n",
      "Epoch 29/50\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.3470 - val_loss: 0.2913\n",
      "Epoch 30/50\n",
      "120/120 [==============================] - 4s 37ms/step - loss: 0.3465 - val_loss: 0.2911\n",
      "Epoch 31/50\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.3464 - val_loss: 0.2910\n",
      "Epoch 32/50\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.3464 - val_loss: 0.2911\n",
      "Epoch 33/50\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.3464 - val_loss: 0.2913\n",
      "Epoch 34/50\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.3464 - val_loss: 0.2912\n",
      "Epoch 35/50\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.3445"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-52-65cdc2d1a331>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[0mmodel2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcompile\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moptimizer\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0moptimizer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mloss\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'mse'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msummary\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 18\u001B[1;33m \u001B[0mtrained_model2\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnormalized_x_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnormalized_y_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m50\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalidation_split\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0.2\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch_size\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mc:\\users\\caleb\\cis4930- pythonlocal\\pitcher\\venv64\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001B[0m in \u001B[0;36m_method_wrapper\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     64\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0m_method_wrapper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     65\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_in_multi_worker_mode\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# pylint: disable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 66\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mmethod\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     67\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     68\u001B[0m     \u001B[1;31m# Running inside `run_distribute_coordinator` already.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\caleb\\cis4930- pythonlocal\\pitcher\\venv64\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m    846\u001B[0m                 batch_size=batch_size):\n\u001B[0;32m    847\u001B[0m               \u001B[0mcallbacks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 848\u001B[1;33m               \u001B[0mtmp_logs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtrain_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    849\u001B[0m               \u001B[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    850\u001B[0m               \u001B[1;31m# This blocks until the batch has finished executing.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\caleb\\cis4930- pythonlocal\\pitcher\\venv64\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    578\u001B[0m         \u001B[0mxla_context\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mExit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    579\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 580\u001B[1;33m       \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    581\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    582\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mtracing_count\u001B[0m \u001B[1;33m==\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_get_tracing_count\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\caleb\\cis4930- pythonlocal\\pitcher\\venv64\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m_call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    609\u001B[0m       \u001B[1;31m# In this case we have created variables on the first call, so we run the\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    610\u001B[0m       \u001B[1;31m# defunned version which is guaranteed to never create variables.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 611\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_stateless_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# pylint: disable=not-callable\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    612\u001B[0m     \u001B[1;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_stateful_fn\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    613\u001B[0m       \u001B[1;31m# Release the lock early so that multiple threads can perform the call\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\caleb\\cis4930- pythonlocal\\pitcher\\venv64\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2418\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2419\u001B[0m       \u001B[0mgraph_function\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_maybe_define_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2420\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mgraph_function\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_filtered_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# pylint: disable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2421\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2422\u001B[0m   \u001B[1;33m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\caleb\\cis4930- pythonlocal\\pitcher\\venv64\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m_filtered_call\u001B[1;34m(self, args, kwargs)\u001B[0m\n\u001B[0;32m   1659\u001B[0m       \u001B[0;31m`\u001B[0m\u001B[0margs\u001B[0m\u001B[0;31m`\u001B[0m \u001B[1;32mand\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m`\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;31m`\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1660\u001B[0m     \"\"\"\n\u001B[1;32m-> 1661\u001B[1;33m     return self._call_flat(\n\u001B[0m\u001B[0;32m   1662\u001B[0m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001B[0;32m   1663\u001B[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001B[1;32mc:\\users\\caleb\\cis4930- pythonlocal\\pitcher\\venv64\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1743\u001B[0m         and executing_eagerly):\n\u001B[0;32m   1744\u001B[0m       \u001B[1;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1745\u001B[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001B[0m\u001B[0;32m   1746\u001B[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[0;32m   1747\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001B[1;32mc:\\users\\caleb\\cis4930- pythonlocal\\pitcher\\venv64\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36mcall\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    591\u001B[0m       \u001B[1;32mwith\u001B[0m \u001B[0m_InterpolateFunctionError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    592\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mcancellation_manager\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 593\u001B[1;33m           outputs = execute.execute(\n\u001B[0m\u001B[0;32m    594\u001B[0m               \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msignature\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    595\u001B[0m               \u001B[0mnum_outputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_num_outputs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\caleb\\cis4930- pythonlocal\\pitcher\\venv64\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     57\u001B[0m   \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     58\u001B[0m     \u001B[0mctx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 59\u001B[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0m\u001B[0;32m     60\u001B[0m                                         inputs, attrs, num_outputs)\n\u001B[0;32m     61\u001B[0m   \u001B[1;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# model2. Trying out less layers\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model2 = Sequential()\n",
    "# 2 LSTM layers\n",
    "model2.add(LSTM(200, input_shape=(50, 3), return_sequences=True))\n",
    "model2.add(LSTM(200))\n",
    "\n",
    "# Dense layers\n",
    "model2.add(Dense(100, activation=\"relu\"))\n",
    "model2.add(Dropout(0.3))\n",
    "\n",
    "# Output Layer\n",
    "model2.add(Dense(3, activation=\"softmax\"))\n",
    "model2.summary()\n",
    "model2.compile(optimizer=optimizer, loss='mse')\n",
    "print(model2.summary())\n",
    "trained_model2 = model2.fit(normalized_x_train, normalized_y_train, epochs=50, validation_split=0.2, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_24 (LSTM)               (None, 50, 200)           163200    \n",
      "_________________________________________________________________\n",
      "lstm_25 (LSTM)               (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 504,403\n",
      "Trainable params: 504,403\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 50, 512)           1056768   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 512)               2099200   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                3250      \n",
      "=================================================================\n",
      "Total params: 3,192,050\n",
      "Trainable params: 3,192,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = harmony_maker.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# compile model\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}